{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75656468-1c28-468d-aaeb-a7f91b16cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "# Figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Ipython notebook basics\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import sys\n",
    "sys.setrecursionlimit(5000)\n",
    "\n",
    "# Things I use everytime\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "#import scipy.stats as stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06eadad-f4e5-4650-b75b-8d235460939c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameter tagged cell for papermill\n",
    "filename = \"default\"\n",
    "#iso_seq_gene = pd.read_csv(f\"/mmfs1/gscratch/stergachislab/yhhc/projects/Iso-seq_public/Cyclo_noncyclo_comparison/Analysis/6.10.24/3.Compare_samples/3.Novel_iso_abundance_in_gene/data_combined_full_gene_with_Hyp5.csv\",sep=\",\")\n",
    "#iso_seq_gene = pd.read_csv(f\"/mmfs1/gscratch/stergachislab/yhhc/projects/Iso-seq_public/Cyclo_noncyclo_comparison/Analysis/6.10.24/3.Compare_samples/1.Isoform/data_combined_full.csv\",sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3564d9-a3cf-415f-a95a-b37897f0ac42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'default'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m iso_seq_gene \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/mmfs1/gscratch/stergachislab/yhhc/tools/miniconda3/miniconda3/envs/jupyter-notebook/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'default'"
     ]
    }
   ],
   "source": [
    "iso_seq_gene = pd.read_csv(filename,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ce64c-0422-4521-9a54-d6914a1431e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove isoforms with low counts in all patients.\n",
    "\n",
    "# Define count threshold\n",
    "count_threshold = 10\n",
    "\n",
    "# Group by 'Isoform_PBid' and check if any counts meet the threshold\n",
    "isoforms_to_keep = iso_seq_gene.groupby('Isoform_PBid').apply(\n",
    "    lambda group: any(group['cyclo_count'] >= count_threshold) or any(group['noncyclo_count'] >= count_threshold)\n",
    ")\n",
    "\n",
    "# Filter to keep only isoforms that meet the threshold\n",
    "isoforms_to_keep = isoforms_to_keep[isoforms_to_keep].index.tolist()\n",
    "\n",
    "# Print helpful statements\n",
    "print(\"Number of isoforms to keep after filtering based on counts:\")\n",
    "print(len(isoforms_to_keep))\n",
    "\n",
    "# Filter the data_with_totals to keep only the desired Isoform_PBid\n",
    "iso_seq_gene = iso_seq_gene[iso_seq_gene['Isoform_PBid'].isin(isoforms_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d5285-3bcf-4195-a4a7-72b1a004f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prop_novel\n",
    "iso_seq_gene['prop_novel'] = (iso_seq_gene['proportion_in_Bin1_cyclo'] - iso_seq_gene['proportion_in_Bin1_noncyclo']) / (iso_seq_gene['proportion_in_Bin1_cyclo'] + iso_seq_gene['proportion_in_Bin1_noncyclo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76bd4b-06c6-46ed-a3b7-8df669ce31a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the iso_seq_gene pd dataframe, I have a column called Cyclo_TPM and another column called Noncyclo_TPM.\n",
    "# I want to create a column called test_statistic that is calculated by doing this:\n",
    "# ratio = (Cyclo_TPM+1)/(Noncyclo_TPM+1)\n",
    "# absolute_diff = abs(Cyclo_TPM - Noncyclo_TPM)\n",
    "# test_statistic = log2(ratio) * log2(5*absolute_diff)\n",
    "\n",
    "df = iso_seq_gene\n",
    "\n",
    "# Calculate the adjusted ratio\n",
    "df['ratio_cyclo'] = (df['Total_bin_cyclo_count_Bin1_le']) / (df['cyclo_count']+ 1)\n",
    "df['ratio_noncyclo'] = (df['Total_bin_noncyclo_count_Bin1_le']) / (df['noncyclo_count'] + 1)\n",
    "#df['ratio'] = (df['ratio_cyclo'] + 0.001) / (df['ratio_noncyclo'] + 0.001)\n",
    "\n",
    "df['test_statistic'] = (\n",
    "    (df['ratio_cyclo'] - df['ratio_noncyclo'])\n",
    "    * np.log2(df['Total_bin_cyclo_count_Bin1_le'] + 1) \n",
    "    * np.log2(df['Total_bin_noncyclo_count_Bin2_g'] + 1)\n",
    ")\n",
    "\n",
    "#df['test_statistic'] = (df['ratio_cyclo']-df['ratio_noncyclo']) * np.log2(df['Total_bin_cyclo_count_Bin1_le_TPM'] + 1) * np.log2(df['Total_bin_noncyclo_count_Bin2_g_TPM'] + 1) \n",
    "\n",
    "\n",
    "# # V1: \n",
    "# # Using TPM improves the ranking for MFN2. It also decreases the skewness for the over-sequenced samples. \n",
    "# df['Total_bin_cyclo_count_Bin1_le_TPM'] = (df['Total_bin_cyclo_count_Bin1_le'] / df['cyclo_total_sum']) * 1000000\n",
    "# df['test_statistic'] = (df['ratio_cyclo']-df['ratio_noncyclo']) * np.log2(df['Total_bin_cyclo_count_Bin1_le_TPM'] + 1) #This works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b41d3-5dd7-4ac4-a606-4d91acf7ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-score, compares patient to other patients.\n",
    "\n",
    "# # Function to calculate the z-score for each row within a group\n",
    "# def calculate_z_score_within_group(group):\n",
    "#     group = group.copy()  # Avoid SettingWithCopyWarning\n",
    "#     for i, row in group.iterrows():\n",
    "#         other_test_statistics = group.loc[group.index != i, 'test_statistic']\n",
    "#         mean_others = other_test_statistics.mean()\n",
    "#         sd_all = group['test_statistic'].std()\n",
    "#         group.at[i, 'z_score'] = (row['test_statistic'] - mean_others) / sd_all\n",
    "#     return group\n",
    "\n",
    "# Function to calculate the z-score for each row within a group\n",
    "def calculate_z_score_within_group(group):\n",
    "    group = group.copy()  # Avoid SettingWithCopyWarning\n",
    "    for i, row in group.iterrows():\n",
    "        other_test_statistics = group.loc[group.index != i, 'test_statistic']\n",
    "        median_others = other_test_statistics.median()\n",
    "        sd_all = group['test_statistic'].std()\n",
    "\n",
    "        if sd_all == 0:\n",
    "            group['z_score'] = 0\n",
    "        else:\n",
    "            group.at[i, 'z_score'] = (row['test_statistic'] - median_others) / sd_all\n",
    "            # Can't use IQR because iqr is 0 for the HARS1 positive control case and causes division by zero. \n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "df = df.groupby('Isoform_PBid').apply(calculate_z_score_within_group)\n",
    "\n",
    "# Reset index to clean up the DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "#[T1 - mean(T2,...,T18)]/SD(T1,....,T18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8126f-f039-4003-97b0-04b509659bc2",
   "metadata": {},
   "source": [
    "## Histogram of test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e872abd-0ac0-4247-956e-46533b313232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values from the test_statistic column for plotting\n",
    "test_statistic_values = df['test_statistic'].dropna()\n",
    "\n",
    "# Create a histogram of the test_statistic values\n",
    "plt.hist(test_statistic_values, bins=100, edgecolor='black')\n",
    "plt.xlabel('Test Statistic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Test Statistic Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26535e6f-b437-473c-8753-9f98b04ae1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_statistic_values, bins=100, edgecolor='black')\n",
    "plt.xlabel('Test Statistic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Zoomed in Histogram of Test Statistic Values')\n",
    "plt.xlim(-3, 3)  # Set x-axis range from -25 to 25\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be62a53-163e-4bec-a27e-652acf629cf2",
   "metadata": {},
   "source": [
    "## Summary stats of test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed3a0c-aaf8-4e89-aa24-35c84ad38207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values from the test_statistic column\n",
    "test_statistic_values = df['test_statistic'].dropna() # NA occurs when the abs diff is 0 and you take log2(0)\n",
    "\n",
    "# Get summary statistics\n",
    "summary_stats = test_statistic_values.describe()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06092241-d37d-47c3-a12c-2b66d70f48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The amount of NAs should equal the amount of rows with abs diff of 0. LEFT OFF HERE\n",
    "# num_na_values = df['test_statistic'].isna().sum()\n",
    "\n",
    "# # Count the number of rows where absolute_diff is zero\n",
    "# num_abs_diff_zero = (df['absolute_diff'] == 0).sum()\n",
    "\n",
    "# print(\"\\nNumber of NaN values in test_statistic:\", num_na_values)\n",
    "# print(\"Number of rows with absolute_diff equal to 0:\", num_abs_diff_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641b5d7-c121-41a3-b506-b2071c7a65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row with the max test_statistic\n",
    "max_test_statistic_row = df.loc[df['test_statistic'].idxmax()]\n",
    "\n",
    "# Get the row with the min test_statistic\n",
    "min_test_statistic_row = df.loc[df['test_statistic'].idxmin()]\n",
    "\n",
    "max_min_test_statistic_df = pd.DataFrame([max_test_statistic_row, min_test_statistic_row])\n",
    "\n",
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "max_min_test_statistic_df\n",
    "\n",
    "# Reset to default after displaying\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734c903-6fb3-4831-af71-d7e8f190f6d6",
   "metadata": {},
   "source": [
    "## Correlation of test statistic with P_Value_Hyp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066ad9d-a79e-49da-8321-7a06dbd3fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Calculate the negative log of P_Value_Hyp1\n",
    "# df['neg_log_P_Value_Hyp5'] = -np.log10(df['P_Value_Hyp5'])\n",
    "\n",
    "# # Filter the DataFrame to only include rows where NormalizedFractionDifference > 0\n",
    "# filtered_df = df[df['prop_novel'] > 0]\n",
    "\n",
    "# # Drop NaN values from the test_statistic and neg_log_P_Value_Hyp1 columns for correlation analysis\n",
    "# filtered_df = filtered_df.dropna(subset=['test_statistic', 'neg_log_P_Value_Hyp5'])\n",
    "\n",
    "# # Calculate the correlation value\n",
    "# correlation_value = filtered_df[['test_statistic', 'neg_log_P_Value_Hyp5']].corr().loc['test_statistic', 'neg_log_P_Value_Hyp5']\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(filtered_df['test_statistic'], filtered_df['neg_log_P_Value_Hyp5'], alpha=0.5)\n",
    "# plt.xlabel('Test Statistic')\n",
    "# plt.ylabel('-log10(P_Value_Hyp5)')\n",
    "# plt.title(f'Scatter Plot of Test Statistic with prop_novel >0 vs. -log10(P_Value_Hyp5)\\nCorrelation: {correlation_value:.2f}')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4f7b8-5704-430c-9a51-5a049b146893",
   "metadata": {},
   "source": [
    "## Histogram of z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4e4b2-d490-4826-8d5d-11e71138d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values from the test_statistic column for plotting\n",
    "z_score_values = df['z_score'].dropna()\n",
    "\n",
    "# Create a histogram of the test_statistic values\n",
    "plt.hist(z_score_values, bins=100, edgecolor='black')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Z-Score Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d64794-f677-4783-b1b9-fa4f04b4e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_values = df['z_score'].dropna()\n",
    "z_score_values = z_score_values[(z_score_values >= -50) & (z_score_values <= 50)]\n",
    "\n",
    "\n",
    "plt.hist(z_score_values, bins=100, edgecolor='black')\n",
    "plt.xlabel('Z-Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Zoomed in Histogram of Z-score Values')\n",
    "plt.xlim(-25, 25)  # Set x-axis range from -25 to 25\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac51bc0c-a683-42d4-9427-a7146b0a0067",
   "metadata": {},
   "source": [
    "## Summary stats of z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8fa48-e620-475d-9599-b5ce575b41de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values from the test_statistic column\n",
    "z_score_values = df['z_score'].dropna() # NA occurs when the abs diff is 0 and you take log2(0)\n",
    "\n",
    "# Get summary statistics\n",
    "summary_stats_z_score = z_score_values.describe()\n",
    "summary_stats_z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745fab7-24f5-44c2-a4a1-637e3faa224b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbcf92a-990b-4df3-8ad6-684ca9333f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row with the max test_statistic\n",
    "max_z_score_row = df.loc[df['z_score'].idxmax()]\n",
    "\n",
    "# Get the row with the min test_statistic\n",
    "min_z_score_row = df.loc[df['z_score'].idxmin()]\n",
    "\n",
    "max_min_z_score_df = pd.DataFrame([max_z_score_row, min_z_score_row])\n",
    "\n",
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "max_min_z_score_df\n",
    "\n",
    "# Reset to default after displaying\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53143b07-53dd-4c94-9d81-1a4e5183477d",
   "metadata": {},
   "source": [
    "## Correlation of z-score with P_Value_Hyp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d845ac6f-5e78-48d7-9d32-24f5bd0c40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Calculate the negative log of P_Value_Hyp1\n",
    "# df['neg_log_P_Value_Hyp5'] = -np.log10(df['P_Value_Hyp5'])\n",
    "\n",
    "# # Filter the DataFrame to only include rows where NormalizedFractionDifference > 0\n",
    "# filtered_df = df[df['prop_novel'] > 0]\n",
    "\n",
    "# # Drop NaN values from the test_statistic and neg_log_P_Value_Hyp1 columns for correlation analysis\n",
    "# filtered_df = filtered_df.dropna(subset=['z_score', 'neg_log_P_Value_Hyp5'])\n",
    "\n",
    "# # Calculate the correlation value\n",
    "# correlation_value = filtered_df[['z_score', 'neg_log_P_Value_Hyp5']].corr().loc['z_score', 'neg_log_P_Value_Hyp5']\n",
    "\n",
    "# # Create the scatter plot\n",
    "# plt.scatter(filtered_df['z_score'], filtered_df['neg_log_P_Value_Hyp5'], alpha=0.5)\n",
    "# plt.xlabel('z_score')\n",
    "# plt.ylabel('-log10(P_Value_Hyp5)')\n",
    "# plt.title(f'Scatter Plot of Z-Score with prop_novel >0 vs. -log10(P_Value_Hyp5)\\nCorrelation: {correlation_value:.2f}')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff73528-466b-49cc-bfa1-e987b39b6e80",
   "metadata": {},
   "source": [
    "## Write outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfb9e6-6bcb-46d9-a3c7-d4234aedb277",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('test_statistic_hyp5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b6292-4e04-41c7-9ad9-a93c0b51679d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Function to save variables\n",
    "def save_variables(filename, variables):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(variables, f)\n",
    "\n",
    "# Save specific variables\n",
    "variables_to_save = {\n",
    "    'df': df\n",
    "}\n",
    "save_variables('Test_statistic_hyp5_notebook_variables.pkl', variables_to_save)\n",
    "\n",
    "# Load variables from a file\n",
    "# def load_variables(filename):\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         variables = pickle.load(f)\n",
    "#     return variables\n",
    "\n",
    "# # Load the variables\n",
    "# loaded_variables = load_variables('notebook_variables.pkl')\n",
    "\n",
    "# # Access the loaded variables\n",
    "# df = loaded_variables['df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9001c975-c58e-4d19-ae09-19c54726b36e",
   "metadata": {},
   "source": [
    "## Positive controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be27b8-bd86-4436-aafa-de0fa935c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the positive control cases.\n",
    "\n",
    "#UDN212054 HARS1\n",
    "#UDN633333 MFN2\n",
    "#UDN215640 SET\n",
    "\n",
    "# Define the pairs to match\n",
    "matching_pairs = {\n",
    "    'UDN212054': 'HARS1',\n",
    "    'UDN633333': 'MFN2',\n",
    "    'UDN215640': 'SET'\n",
    "}\n",
    "\n",
    "# Filter the DataFrame based on the matching pairs\n",
    "filtered_df = df[df.apply(lambda row: matching_pairs.get(row['Sample']) == row['associated_gene'], axis=1)]\n",
    "\n",
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#data_df[data_df['associated_gene'] == 'MFN2']\n",
    "filtered_df\n",
    "\n",
    "# Reset to default after displaying\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_rows')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fceead6-6495-4eb8-8d1b-0cf04fa2a793",
   "metadata": {},
   "source": [
    "## SRSF6 cassette exon positive control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbaf62-71a2-4dfd-99a1-1ea92841f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df[df['associated_gene'] == 'SRSF6']\n",
    "\n",
    "# Reset to default after displaying\n",
    "pd.reset_option('display.max_columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc4b89-fc1f-430e-8e6e-919972f2ae39",
   "metadata": {},
   "source": [
    "## Histogram of Z-score in a single patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39fdaa-9894-40a4-8c9e-8f4daa78118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique samples\n",
    "unique_samples = df['Sample'].unique()\n",
    "\n",
    "# Create subplots\n",
    "num_samples = len(unique_samples)\n",
    "num_cols = 3\n",
    "num_rows = (num_samples + num_cols - 1) // num_cols\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 5))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, sample in enumerate(unique_samples):\n",
    "    filtered_df = df[df['Sample'] == sample]\n",
    "    z_score_values = filtered_df['z_score'].dropna()\n",
    "    \n",
    "    # Create histogram in the appropriate subplot\n",
    "    axes[i].hist(z_score_values, bins=100, edgecolor='black')\n",
    "    axes[i].set_xlabel('Z-Score')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f'Histogram of Z-Score Values for Sample {sample}')\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfecd2de-4439-4b05-9189-09e0fdf7348f",
   "metadata": {},
   "source": [
    "## Z-score vs test-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59aabf-5612-46ec-8548-d78ade3f0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows for the sample 'UDN212054'\n",
    "filtered_df = df[df['Sample'] == 'UDN633333']\n",
    "\n",
    "# Create a scatter plot with different colors\n",
    "colors = ['red' if gene == 'MFN2' else 'blue' for gene in filtered_df['associated_gene']]\n",
    "plt.scatter(filtered_df['test_statistic'], filtered_df['z_score'], c=colors, edgecolor='black')\n",
    "\n",
    "# Label points where associated_gene is 'HARS1'\n",
    "for i, row in filtered_df.iterrows():\n",
    "    if row['associated_gene'] == 'MFN2':\n",
    "        plt.annotate('MFN2', (row['test_statistic'], row['z_score']),\n",
    "                     textcoords=\"offset points\", xytext=(5,5), ha='center', color='red')\n",
    "\n",
    "plt.xlabel('Test Statistic')\n",
    "plt.ylabel('Z-Score')\n",
    "plt.title('Scatter Plot of Z-Score vs Test Statistic for Sample UDN633333')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8a9a8-0da1-4a0b-9e98-475f1e4bac4f",
   "metadata": {},
   "source": [
    "## Plotting prop_novel against Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac53498-e998-4a31-8c3c-b36e7bf4cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows for the sample 'UDN212054'\n",
    "filtered_df = df[df['Sample'] == 'UDN633333']\n",
    "\n",
    "# Create a scatter plot\n",
    "colors = ['red' if gene == 'MFN2' else 'blue' for gene in filtered_df['associated_gene']]\n",
    "plt.scatter(filtered_df['prop_novel'], filtered_df['z_score'], c=colors, edgecolor='black')\n",
    "\n",
    "# Label points where associated_gene is 'HARS1'\n",
    "for i, row in filtered_df.iterrows():\n",
    "    if row['associated_gene'] == 'MFN2':\n",
    "        plt.annotate('MFN2', (row['prop_novel'], row['z_score']),\n",
    "                     textcoords=\"offset points\", xytext=(5,5), ha='center', color='red')\n",
    "\n",
    "plt.xlabel('prop_novel')\n",
    "plt.ylabel('Z-Score')\n",
    "plt.title('Scatter Plot of Z-Score vs prop_novel for Sample UDN633333')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62c868-b52e-4374-bc76-af567a5b4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum z-score value\n",
    "max_z_score = df['z_score'].max()\n",
    "\n",
    "# Filter the DataFrame to include only rows with the maximum z-score\n",
    "max_z_score_rows = df[df['z_score'] == max_z_score]\n",
    "\n",
    "# Calculate the number of rows with the maximum z-score\n",
    "num_max_z_score_rows = len(max_z_score_rows)\n",
    "\n",
    "print(f\"The number of rows with the maximum z-score is: {num_max_z_score_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdacebec-cd70-4427-9f3e-8877d5d7474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_z_score_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfd5bd-3f2b-4f1e-a799-8cee11bf5413",
   "metadata": {},
   "source": [
    "## Rank of positive control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dd010-bb0a-4940-84da-7a7152a57b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the percentiles to check\n",
    "percentiles = [99.9, 99.5, 99, 98, 95, 90, 80, 50]\n",
    "\n",
    "# Filter the DataFrame to include only rows for the sample 'UDN212054'\n",
    "sample_df = df[df['Sample'] == 'UDN633333']\n",
    "sample_df = sample_df[sample_df['prop_novel'] > 0]\n",
    "\n",
    "\n",
    "# Loop through each percentile, calculate and print the rank\n",
    "for percentile in percentiles:\n",
    "    # Calculate the percentile of the z-scores within this sample\n",
    "    percentile_value = np.percentile(sample_df['z_score'], percentile)\n",
    "\n",
    "    \n",
    "    # Filter the DataFrame to include only rows with z-scores above this percentile within the sample\n",
    "    top_percentile_df = sample_df[sample_df['z_score'] > percentile_value]\n",
    "    \n",
    "    # Sort the filtered DataFrame by the test statistic in descending order\n",
    "    sorted_df = top_percentile_df.sort_values(by='test_statistic', ascending=False)\n",
    "    \n",
    "    # Reset the index to create a ranking\n",
    "    sorted_df = sorted_df.reset_index(drop=True)\n",
    "    \n",
    "    try:\n",
    "        # Determine the rank of 'HARS1' in the sorted DataFrame\n",
    "        hars1_rank = sorted_df[sorted_df['associated_gene'] == 'MFN2'].index[0] + 1  # Adding 1 to convert zero-based index to rank\n",
    "        print(f\"The rank of MFN2 in terms of test statistic among the top {percentile} percentile of z-scores in UDN633333 is: {hars1_rank}\")\n",
    "    except IndexError:\n",
    "        print(f\"MFN2 is not in the top {percentile} percentile of z-scores in UDN633333.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84b084-b62e-4a96-a567-68c29b4e7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "sorted_df.head(22)\n",
    "\n",
    "# Reset the display option to its default value\n",
    "pd.reset_option('display.max_columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1248287-8555-430e-83b7-c45dee989d96",
   "metadata": {},
   "source": [
    "## Volcano plot replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f877bb45-0d5e-416c-a81a-fc65988b2cd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## For the top 5% of isoforms in UDN212054 based on z-score, plot the NormalizedFractionDifference vs test_statistic. \n",
    "# Label and color red the HARS1 isoforms.\n",
    "# Filter the DataFrame to include only rows for the sample 'UDN212054'\n",
    "sample_df = df[df['Sample'] == 'UDN633333']\n",
    "sample_df = sample_df[sample_df['prop_novel'] > 0]\n",
    "\n",
    "# Calculate the 95th percentile of the z-scores within this sample\n",
    "percentile_95 = np.percentile(sample_df['z_score'], 99)\n",
    "\n",
    "# Filter the DataFrame to include only the top 5% isoforms based on z_score\n",
    "top_5_percent_df = sample_df[sample_df['z_score'] > percentile_95]\n",
    "\n",
    "# Plot NormalizedFractionDifference vs test_statistic\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(top_5_percent_df['prop_novel'], top_5_percent_df['test_statistic'], color='blue', label='Isoforms')\n",
    "\n",
    "# Highlight and label HARS1 isoforms\n",
    "for i, row in top_5_percent_df.iterrows():\n",
    "    if row['associated_gene'] == 'MFN2':\n",
    "        plt.scatter(row['prop_novel'], row['test_statistic'], color='red', label='MFN2')\n",
    "        plt.annotate('MFN2', (row['prop_novel'], row['test_statistic']),\n",
    "                     textcoords=\"offset points\", xytext=(0,10), ha='center', color='red')\n",
    "\n",
    "plt.xlabel('prop_novel')\n",
    "plt.ylabel('Test Statistic')\n",
    "plt.title('prop_novel vs Test Statistic for Top 1% Genes in UDN633333 based on z-score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc162b5-718f-4dc2-b3c9-7c9c7fe8c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all variables\n",
    "%reset -f\n",
    "\n",
    "# Additional cleanup if needed\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
